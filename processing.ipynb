{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "388258de",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "720f1410",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T13:46:34.618547Z",
     "start_time": "2023-04-07T13:46:33.168786Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.Utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff91e4a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T13:47:09.051446Z",
     "start_time": "2023-04-07T13:46:48.926372Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing training dataset\n",
    "TRAIN = pd.read_csv(filepath_or_buffer=Utils.FILENAMES[\"TRAIN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aee3785",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T13:47:13.782978Z",
     "start_time": "2023-04-07T13:47:11.671551Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing second training dataset\n",
    "TRAIN_2 = pd.read_csv(filepath_or_buffer=Utils.FILENAMES[\"TRAIN_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243a4637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing test dataset\n",
    "TEST = pd.read_csv(filepath_or_buffer=Utils.FILENAMESNAMES[\"TEST\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf8516f",
   "metadata": {},
   "source": [
    "After an in-depth visualization, we have observed that the few samples contained inside the `TEST` dataset are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df95eddf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T13:47:21.264673Z",
     "start_time": "2023-04-07T13:47:21.260562Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify the continuity of the time series\n",
    "#TRAIN.tail()\n",
    "#TRAIN_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd84a9b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T13:48:02.790732Z",
     "start_time": "2023-04-07T13:48:01.521077Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merging TRAIN and TRAIN_2 as df\n",
    "df = pd.concat([TRAIN, TRAIN_2], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d147beb5",
   "metadata": {},
   "source": [
    "**Comments**:\n",
    "- First timestamp: **2018-01-01 00:01:00**\n",
    "- Last timestamp: **2022-01-24 00:00:00**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e17c0e0",
   "metadata": {},
   "source": [
    "We are now:\n",
    "1. Splitting our dataframe by `asset_id`\n",
    "2. Removing unnecessary columns\n",
    "3. Converting the timestamp as a pandas `DateTime` object\n",
    "4. Setting this datetime as index\n",
    "5. Performing some additional operations to compress the data and remove some non-expected precision\n",
    "6. Saving to disk as CSV and Parquet files for each `asset_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03936835",
   "metadata": {},
   "source": [
    "For instance, the column `Count` is an integer-value property by definition.\n",
    "However, our dataset and/or import procedure casted it as a floatting-point number.\n",
    "\n",
    "$\\longrightarrow$ We will reduce this precision using the `.astype()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "49904aed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T14:45:30.333745Z",
     "start_time": "2023-04-07T14:42:03.760868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Processing Asset #0 \t (Binance Coin)\n",
      "--> Processing Asset #1 \t (Bitcoin)\n",
      "--> Processing Asset #2 \t (Bitcoin Cash)\n",
      "--> Processing Asset #3 \t (Cardano)\n",
      "--> Processing Asset #4 \t (Dogecoin)\n",
      "--> Processing Asset #5 \t (EOS.IO)\n",
      "--> Processing Asset #6 \t (Ethereum)\n",
      "--> Processing Asset #7 \t (Ethereum Classic)\n",
      "--> Processing Asset #8 \t (IOTA)\n",
      "--> Processing Asset #9 \t (Litecoin)\n",
      "--> Processing Asset #10 \t (Maker)\n",
      "--> Processing Asset #11 \t (Monero)\n",
      "--> Processing Asset #12 \t (Stellar)\n",
      "--> Processing Asset #13 \t (TRON)\n"
     ]
    }
   ],
   "source": [
    "# Hashmap of train datasets for each asset id\n",
    "df_dict = {asset_id: None for asset_id in Utils.ASSET_IDS}\n",
    "\n",
    "# For each asset id, perform the pre-processing\n",
    "for asset_id in Utils.ASSET_IDS:\n",
    "    print(f\"--> Processing Asset #{asset_id} \\t ({Utils.get_asset_name(asset_id)})\")\n",
    "    \n",
    "    # Retrieving the corresponding data rows\n",
    "    df_dict[asset_id] = df[df[\"Asset_ID\"] == asset_id]\n",
    "    \n",
    "    # Removing the Asset_ID column (useless now)\n",
    "    try:\n",
    "        df_dict[asset_id].drop([\"Asset_ID\", \"Target\"], axis=1, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Converting the timestamp column\n",
    "    df_dict[asset_id][\"timestamp\"] = pd.to_datetime(arg=df_dict[asset_id][\"timestamp\"], \n",
    "                                                     unit=\"s\", \n",
    "                                                     errors=\"ignore\")\n",
    "    # Setting the timestamp column as index column\n",
    "    df_dict[asset_id].set_index([\"timestamp\"], inplace=True)\n",
    "    \n",
    "    # Converting the Count number\n",
    "    df_dict[asset_id][\"Count\"] = pd.to_numeric(arg=df_dict[asset_id][\"Count\"], \n",
    "                                               downcast=\"integer\")\n",
    "\n",
    "    # Saving it to a new CSV file in assets/\n",
    "    df_dict[asset_id].to_csv(path_or_buf=f\"assets/csv/{asset_id}.csv\")\n",
    "    \n",
    "    # Saving it to a new Parquet file in assets/ (better for file I/O speed & compression)\n",
    "    table = pa.Table.from_pandas(df=df_dict[asset_id])\n",
    "    pq.write_table(table=table, where=f\"assets/parquet/{asset_id}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8360ec57",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971a27bb",
   "metadata": {},
   "source": [
    "We want to check if the sum of the number of rows for each `asset_id` is equal to the number of rows from the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e7cf7a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T13:53:52.666779Z",
     "start_time": "2023-04-07T13:53:52.663402Z"
    }
   },
   "outputs": [],
   "source": [
    "assert sum([df_dict[k].shape[0] for k in Utils.ASSET_IDS]) == df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83b3a9b",
   "metadata": {},
   "source": [
    "We can also check the memory usage of the newly created pandas DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9058f3e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T13:54:32.557322Z",
     "start_time": "2023-04-07T13:54:32.528110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global mem. usage: \t 1.7 GB\n"
     ]
    }
   ],
   "source": [
    "# Computing the memory usage of each DataFrame\n",
    "MEM_USAGE = {asset_id: df_dict[asset_id].memory_usage(index=True).sum()/10**6 for asset_id in Utils.ASSET_IDS}\n",
    "\n",
    "# Computing the global memory usage\n",
    "GLOBAL_MEM_USAGE = sum(list(MEM_USAGE.values()))/10**3\n",
    "print(f\"Global mem. usage: \\t {GLOBAL_MEM_USAGE :.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c118eb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T14:14:12.395062Z",
     "start_time": "2023-04-07T14:14:12.221849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>VWAP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:01:00</th>\n",
       "      <td>229.0</td>\n",
       "      <td>13835.194000</td>\n",
       "      <td>14013.8</td>\n",
       "      <td>13666.11</td>\n",
       "      <td>13850.176000</td>\n",
       "      <td>31.550062</td>\n",
       "      <td>13827.062093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:02:00</th>\n",
       "      <td>235.0</td>\n",
       "      <td>13835.036000</td>\n",
       "      <td>14052.3</td>\n",
       "      <td>13680.00</td>\n",
       "      <td>13828.102000</td>\n",
       "      <td>31.046432</td>\n",
       "      <td>13840.362591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:03:00</th>\n",
       "      <td>528.0</td>\n",
       "      <td>13823.900000</td>\n",
       "      <td>14000.4</td>\n",
       "      <td>13601.00</td>\n",
       "      <td>13801.314000</td>\n",
       "      <td>55.061820</td>\n",
       "      <td>13806.068014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:04:00</th>\n",
       "      <td>435.0</td>\n",
       "      <td>13802.512000</td>\n",
       "      <td>13999.0</td>\n",
       "      <td>13576.28</td>\n",
       "      <td>13768.040000</td>\n",
       "      <td>38.780529</td>\n",
       "      <td>13783.598101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:05:00</th>\n",
       "      <td>742.0</td>\n",
       "      <td>13766.000000</td>\n",
       "      <td>13955.9</td>\n",
       "      <td>13554.44</td>\n",
       "      <td>13724.914000</td>\n",
       "      <td>108.501637</td>\n",
       "      <td>13735.586842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-23 23:56:00</th>\n",
       "      <td>1221.0</td>\n",
       "      <td>36278.361667</td>\n",
       "      <td>36331.0</td>\n",
       "      <td>36249.00</td>\n",
       "      <td>36293.123333</td>\n",
       "      <td>30.247067</td>\n",
       "      <td>36289.796806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-23 23:57:00</th>\n",
       "      <td>1634.0</td>\n",
       "      <td>36289.681667</td>\n",
       "      <td>36328.0</td>\n",
       "      <td>36230.72</td>\n",
       "      <td>36261.708333</td>\n",
       "      <td>35.647000</td>\n",
       "      <td>36276.229399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-23 23:58:00</th>\n",
       "      <td>1570.0</td>\n",
       "      <td>36262.841667</td>\n",
       "      <td>36319.0</td>\n",
       "      <td>36230.30</td>\n",
       "      <td>36276.223333</td>\n",
       "      <td>49.867700</td>\n",
       "      <td>36274.441548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-23 23:59:00</th>\n",
       "      <td>1459.0</td>\n",
       "      <td>36268.849570</td>\n",
       "      <td>36313.0</td>\n",
       "      <td>36231.71</td>\n",
       "      <td>36276.623333</td>\n",
       "      <td>43.030556</td>\n",
       "      <td>36274.613301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-24 00:00:00</th>\n",
       "      <td>2917.0</td>\n",
       "      <td>36262.038571</td>\n",
       "      <td>36302.0</td>\n",
       "      <td>36176.45</td>\n",
       "      <td>36221.987143</td>\n",
       "      <td>110.053151</td>\n",
       "      <td>36247.575361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2136278 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Count          Open     High       Low         Close  \\\n",
       "timestamp                                                                    \n",
       "2018-01-01 00:01:00   229.0  13835.194000  14013.8  13666.11  13850.176000   \n",
       "2018-01-01 00:02:00   235.0  13835.036000  14052.3  13680.00  13828.102000   \n",
       "2018-01-01 00:03:00   528.0  13823.900000  14000.4  13601.00  13801.314000   \n",
       "2018-01-01 00:04:00   435.0  13802.512000  13999.0  13576.28  13768.040000   \n",
       "2018-01-01 00:05:00   742.0  13766.000000  13955.9  13554.44  13724.914000   \n",
       "...                     ...           ...      ...       ...           ...   \n",
       "2022-01-23 23:56:00  1221.0  36278.361667  36331.0  36249.00  36293.123333   \n",
       "2022-01-23 23:57:00  1634.0  36289.681667  36328.0  36230.72  36261.708333   \n",
       "2022-01-23 23:58:00  1570.0  36262.841667  36319.0  36230.30  36276.223333   \n",
       "2022-01-23 23:59:00  1459.0  36268.849570  36313.0  36231.71  36276.623333   \n",
       "2022-01-24 00:00:00  2917.0  36262.038571  36302.0  36176.45  36221.987143   \n",
       "\n",
       "                         Volume          VWAP  \n",
       "timestamp                                      \n",
       "2018-01-01 00:01:00   31.550062  13827.062093  \n",
       "2018-01-01 00:02:00   31.046432  13840.362591  \n",
       "2018-01-01 00:03:00   55.061820  13806.068014  \n",
       "2018-01-01 00:04:00   38.780529  13783.598101  \n",
       "2018-01-01 00:05:00  108.501637  13735.586842  \n",
       "...                         ...           ...  \n",
       "2022-01-23 23:56:00   30.247067  36289.796806  \n",
       "2022-01-23 23:57:00   35.647000  36276.229399  \n",
       "2022-01-23 23:58:00   49.867700  36274.441548  \n",
       "2022-01-23 23:59:00   43.030556  36274.613301  \n",
       "2022-01-24 00:00:00  110.053151  36247.575361  \n",
       "\n",
       "[2136278 rows x 7 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pq.read_pandas(source=\"assets/test.parquet\").to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
